{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d6266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (15474, 8)\n",
      "   image_id                 street             citi  n_citi  bed  bath  sqft  \\\n",
      "0         0  1317 Van Buren Avenue  Salton City, CA     317    3   2.0  1560   \n",
      "1         1         124 C Street W      Brawley, CA      48    3   2.0   713   \n",
      "2         2        2304 Clark Road     Imperial, CA     152    3   1.0   800   \n",
      "3         3     755 Brawley Avenue      Brawley, CA      48    3   1.0  1082   \n",
      "4         4  2207 R Carrillo Court     Calexico, CA      55    4   3.0  2547   \n",
      "\n",
      "    price  \n",
      "0  201900  \n",
      "1  228500  \n",
      "2  273950  \n",
      "3  350000  \n",
      "4  385100  \n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\Hassan/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:49<00:00, 955kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 628597548849.6124\n",
      "Epoch 2/10, Loss: 558662822994.0259\n",
      "Epoch 3/10, Loss: 368955591111.1111\n",
      "Epoch 4/10, Loss: 185286386407.52454\n",
      "Epoch 5/10, Loss: 139449092645.0439\n",
      "Epoch 6/10, Loss: 135309324809.26099\n",
      "Epoch 7/10, Loss: 128577655278.80104\n",
      "Epoch 8/10, Loss: 110509096192.6615\n",
      "Epoch 9/10, Loss: 86909784709.62274\n",
      "Epoch 10/10, Loss: 69974084963.8863\n",
      "MAE: 331792.704069063\n",
      "RMSE: 453889.40291520325\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 2. LOAD DATA\n",
    "df = pd.read_csv(\"dataset/socal2.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "X = df[['bed', 'bath', 'sqft']]\n",
    "y = df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# 3. SCALE TABULAR FEATURES\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_df = pd.DataFrame(X_train_scaled, columns=['bed','bath','sqft'])\n",
    "train_df['price'] = y_train.values\n",
    "\n",
    "test_df = pd.DataFrame(X_test_scaled, columns=['bed','bath','sqft'])\n",
    "test_df['price'] = y_test.values\n",
    "\n",
    "# 4. CUSTOM DATASET\n",
    "\n",
    "class HouseDataset(Dataset):\n",
    "    def __init__(self, df, image_dir):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        tabular = torch.tensor(\n",
    "            [row['bed'], row['bath'], row['sqft']],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        price = torch.tensor(row['price'], dtype=torch.float32)\n",
    "        \n",
    "        img_path = os.path.join(self.image_dir, f\"{idx}.jpg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return image, tabular, price\n",
    "\n",
    "# 5. DATALOADER\n",
    "image_dir = \"dataset/socal2/socal_pics\"\n",
    "\n",
    "train_dataset = HouseDataset(train_df, image_dir)\n",
    "test_dataset  = HouseDataset(test_df, image_dir)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "\n",
    "# 6. MULTIMODAL MODEL\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Image branch using pretrained ResNet18\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, 128)\n",
    "        \n",
    "        # Tabular branch\n",
    "        self.tabular_net = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "        \n",
    "        # Combined branch\n",
    "        self.combined = nn.Sequential(\n",
    "            nn.Linear(128 + 32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, image, tabular):\n",
    "        img_feat = self.cnn(image)\n",
    "        tab_feat = self.tabular_net(tabular)\n",
    "        \n",
    "        combined = torch.cat((img_feat, tab_feat), dim=1)\n",
    "        output = self.combined(combined)\n",
    "        \n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "# 7. TRAINING SETUP\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# 8. TRAINING LOOP\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, tabs, targets in train_loader:\n",
    "        images = images.to(device)\n",
    "        tabs = tabs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, tabs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "\n",
    "# 9. EVALUATION\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, tabs, targets in test_loader:\n",
    "        images = images.to(device)\n",
    "        tabs = tabs.to(device)\n",
    "        \n",
    "        outputs = model(images, tabs)\n",
    "        \n",
    "        preds.extend(outputs.cpu().numpy())\n",
    "        actuals.extend(targets.numpy())\n",
    "\n",
    "mae = mean_absolute_error(actuals, preds)\n",
    "rmse = np.sqrt(mean_squared_error(actuals, preds))\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e9469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
